# Created by aigolden
# Source: https://github.com/yaranbarzi/aigolden-TTS
# License: MIT

import base64
import mimetypes
import os
import re
import struct
import time
import zipfile
from google import genai
from google.genai import types
from IPython.display import Audio
from google.colab import userdata
from google.colab import files
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")

def save_binary_file(file_name, data):
    """Save binary data to a file."""
    with open(file_name, "wb") as f:
        f.write(data)
    print(f"âœ… ÙØ§ÛŒÙ„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {file_name}")
    return file_name

def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:
    """Convert audio data to WAV format."""
    parameters = parse_audio_mime_type(mime_type)
    bits_per_sample = parameters["bits_per_sample"]
    sample_rate = parameters["rate"]
    num_channels = 1
    data_size = len(audio_data)
    bytes_per_sample = bits_per_sample // 8
    block_align = num_channels * bytes_per_sample
    byte_rate = sample_rate * block_align
    chunk_size = 36 + data_size  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ù„ ÙØ§ÛŒÙ„ WAV (Ù‡Ø¯Ø± + Ø¯Ø§Ø¯Ù‡)

    header = struct.pack(
        "<4sI4s4sIHHIIHH4sI",
        b"RIFF",
        chunk_size,
        b"WAVE",
        b"fmt ",
        16,  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø²ÛŒØ±Ù‚Ø³Ù…Øª fmt
        1,   # ÙØ±Ù…Øª PCM
        num_channels,
        sample_rate,
        byte_rate,
        block_align,
        bits_per_sample,
        b"data",
        data_size
    )
    return header + audio_data

def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:
    """Parse audio MIME type to extract parameters."""
    bits_per_sample = 16
    rate = 24000  # Ù†Ø±Ø® Ù¾ÛŒØ´â€ŒÙØ±Ø¶

    parts = mime_type.split(";")
    for param in parts:
        param = param.strip()
        if param.lower().startswith("rate="):
            try:
                rate_str = param.split("=", 1)[1]
                rate = int(rate_str)
            except (ValueError, IndexError):
                pass
        elif param.startswith("audio/L"):
            try:
                bits_per_sample = int(param.split("L", 1)[1])
            except (ValueError, IndexError):
                pass
    return {"bits_per_sample": bits_per_sample, "rate": rate}

def load_text_file():
    """Load text file containing only the main text (no prompt)."""
    print("ğŸ“ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯...")
    print("ğŸ’¡ ÙØ§ÛŒÙ„ ÙÙ‚Ø· Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø¨Ø§Ø´Ø¯ (Ù¾Ø±Ø§Ù…Ù¾Øª Ø§Ø² ÙÛŒÙ„Ø¯ Ø¨Ø§Ù„Ø§ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)")
    
    uploaded = files.upload()
    
    if not uploaded:
        print("âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯.")
        return ""
    
    file_name = list(uploaded.keys())[0]
    print(f"âœ… ÙØ§ÛŒÙ„ '{file_name}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯.")
    
    try:
        with open(file_name, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        print(f"ğŸ“– Ù…ØªÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡: {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        print(f"ğŸ“ Ù†Ù…ÙˆÙ†Ù‡ Ù…ØªÙ†: '{content[:100]}{'...' if len(content) > 100 else ''}'")
        
        return content
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
        return ""

def smart_text_split(text, max_size=3800):
    """Split text into chunks without breaking sentences."""
    if len(text) <= max_size:
        return [text]
    
    chunks = []
    current_chunk = ""
    
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 > max_size:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                words = sentence.split()
                temp_chunk = ""
                for word in words:
                    if len(temp_chunk) + len(word) + 1 > max_size:
                        if temp_chunk:
                            chunks.append(temp_chunk.strip())
                            temp_chunk = word
                        else:
                            chunks.append(word[:max_size])
                            word = word[max_size:]
                            while len(word) > max_size:
                                chunks.append(word[:max_size])
                                word = word[max_size:]
                            if word:
                                temp_chunk = word
                    else:
                        temp_chunk += (" " if temp_chunk else "") + word
                current_chunk = temp_chunk
        else:
            current_chunk += (" " if current_chunk else "") + sentence
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def merge_audio_files_func(file_paths, output_path):
    """Merge multiple audio files into one."""
    if not PYDUB_AVAILABLE:
        print("âŒ pydub Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø¯ØºØ§Ù… Ú©Ø±Ø¯.")
        return False
    
    try:
        print(f"ğŸ”— Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¯ØºØ§Ù… {len(file_paths)} ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ...")
        
        combined = AudioSegment.empty()
        
        for i, file_path in enumerate(file_paths):
            if os.path.exists(file_path):
                print(f"ğŸ“ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ {i+1}: {file_path}")
                audio = AudioSegment.from_file(file_path)
                combined += audio
                if i < len(file_paths) - 1:
                    combined += AudioSegment.silent(duration=500)
            else:
                print(f"âš ï¸ ÙØ§ÛŒÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {file_path}")
        
        combined.export(output_path, format="wav")
        print(f"âœ… ÙØ§ÛŒÙ„ Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}")
        return False

def create_zip_file(file_paths, zip_name):
    """Create a zip file containing all audio files."""
    try:
        with zipfile.ZipFile(zip_name, 'w') as zipf:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    zipf.write(file_path, os.path.basename(file_path))
        print(f"ğŸ“¦ ÙØ§ÛŒÙ„ ZIP Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {zip_name}")
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ ZIP: {e}")
        return False

def generate_audio(text_input, prompt_input, selected_voice, output_base_name, 
                   api_key_input_field, model, temperature, use_file=False, 
                   max_chunk_size=3800, sleep_time=2, merge_files=True, 
                   delete_partials=True):
    """
    Generate audio from text input with specified parameters.
    
    Created by aigolden
    Source: https://github.com/yaranbarzi/aigolden-TTS
    License: MIT
    """
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø±...")
    
    global final_audio_file, generated_files
    final_audio_file = None
    generated_files = []

    # Handle file input if enabled
    if use_file:
        print("ğŸ“ Ø­Ø§Ù„Øª ÙØ§ÛŒÙ„ ÙØ¹Ø§Ù„ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„...")
        file_text = load_text_file()
        if not file_text:
            print("âŒ Ø®Ø·Ø§: Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
            return None, None
        text_input = file_text
        print("âœ… Ù…ØªÙ† Ø§Ø² ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
    else:
        print("âŒ¨ï¸ Ø­Ø§Ù„Øª ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø³ØªÛŒ ÙØ¹Ø§Ù„ Ø§Ø³Øª.")

    # API Key Retrieval and Validation
    api_key = None
    if api_key_input_field:
        api_key = api_key_input_field
        print("ğŸ”‘ Ú©Ù„ÛŒØ¯ API Ø§Ø² ÙÛŒÙ„Ø¯ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
    else:
        api_key = userdata.get("GEMINI_API_KEY")
        if api_key:
            print("ğŸ”‘ Ú©Ù„ÛŒØ¯ API Ø§Ø² Colab Secrets Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        else:
            print("âŒ Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ (GEMINI_API_KEY) Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            print("Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ API Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± ÙÛŒÙ„Ø¯ Ø¨Ø§Ù„Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ø¢Ù† Ø±Ø§ Ø¯Ø± Colab Secrets Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯.")
            print("ğŸ’¡ Ø±Ø§Ù‡Ù†Ù…Ø§: Ø±ÙˆÛŒ Ø¢ÛŒÚ©ÙˆÙ† Ù‚ÙÙ„ ğŸ”‘ Ø¯Ø± Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø³Ù…Øª Ú†Ù¾ Colab Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯ØŒ ÛŒÚ© 'Ø±Ø§Ø²' (Secret) Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù†Ø§Ù… `GEMINI_API_KEY` Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯ Ùˆ Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø¯Ø§Ø± Ø¢Ù† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯. Ø³Ù¾Ø³ 'Notebook access' Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯.")
            return None, None

    os.environ["GEMINI_API_KEY"] = api_key
    print("ğŸ”§ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ GEMINI_API_KEY ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯.")

    # Initialize GenAI Client
    try:
        print("ğŸ› ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ù…ÛŒÙ†Ø§ÛŒ...")
        client = genai.Client(
            api_key=os.environ.get("GEMINI_API_KEY"),
        )
        print("âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ù…ÛŒÙ†Ø§ÛŒ: {e}")
        print("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª Ú©Ù„ÛŒØ¯ API Ø®ÙˆØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù„ÛŒØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ø´Ø¯.")
        return None, None

    # Validate Text Input
    if not text_input or text_input.strip() == "":
        print("âŒ Ø®Ø·Ø§: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ú¯ÙØªØ§Ø± Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ†ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        return None, None

    # Split text into chunks
    text_chunks = smart_text_split(text_input, max_chunk_size)
    print(f"ğŸ“Š Ù…ØªÙ† Ø¨Ù‡ {len(text_chunks)} Ù‚Ø·Ø¹Ù‡ ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯.")
    
    for i, chunk in enumerate(text_chunks):
        print(f"ğŸ“ Ù‚Ø·Ø¹Ù‡ {i+1}: {len(chunk)} Ú©Ø§Ø±Ø§Ú©ØªØ±")

    # Generate audio for each chunk
    for i, chunk in enumerate(text_chunks):
        print(f"\nğŸ”Š ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ù‚Ø·Ø¹Ù‡ {i+1}/{len(text_chunks)}...")
        
        final_text = f'"{prompt_input}"\n{chunk}' if prompt_input.strip() else chunk

        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=final_text),
                ],
            ),
        ]
        generate_content_config = types.GenerateContentConfig(
            temperature=temperature,
            response_modalities=[
                "audio",
            ],
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name=selected_voice
                    )
                )
            ),
        )

        try:
            chunk_filename = f"{output_base_name}_part_{i+1:03d}"
            
            for chunk_data in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                if (
                    chunk_data.candidates
                    and chunk_data.candidates[0].content
                    and chunk_data.candidates[0].content.parts
                    and chunk_data.candidates[0].content.parts[0].inline_data
                ):
                    inline_data = chunk_data.candidates[0].content.parts[0].inline_data
                    data_buffer = inline_data.data
                    file_extension = mimetypes.guess_extension(inline_data.mime_type)
                    print(f"â„¹ï¸ MIME Type: {inline_data.mime_type}, Data Size: {len(data_buffer)} bytes")
                    if inline_data.mime_type == "audio/wav":
                        file_extension = ".wav"
                    else:
                        file_extension = ".wav"
                        data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)

                    generated_file_path = save_binary_file(f"{chunk_filename}{file_extension}", data_buffer)
                    generated_files.append(generated_file_path)
                    print(f"âœ… Ù‚Ø·Ø¹Ù‡ {i+1} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {generated_file_path}")
                    break
                else:
                    if chunk_data.text:
                        print(f"â„¹ï¸ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø§Ø² API: {chunk_data.text}")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù‚Ø·Ø¹Ù‡ {i+1}: {e}")
            continue
        
        if i < len(text_chunks) - 1:
            print(f"â±ï¸ Ø§Ù†ØªØ¸Ø§Ø± {sleep_time} Ø«Ø§Ù†ÛŒÙ‡...")
            time.sleep(sleep_time)

    if not generated_files:
        print("âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯!")
        return None, None

    print(f"\nğŸ‰ {len(generated_files)} ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯!")

    # Merge audio files if enabled
    if merge_files and len(generated_files) > 1:
        merged_filename = f"{output_base_name}_merged.wav"
        if merge_audio_files_func(generated_files, merged_filename):
            final_audio_file = merged_filename
            print(f"ğŸµ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡: {merged_filename}")
            
            if delete_partials:
                for file_path in generated_files:
                    try:
                        os.remove(file_path)
                        print(f"ğŸ—‘ï¸ ÙØ§ÛŒÙ„ Ø¬Ø²Ø¦ÛŒ Ø­Ø°Ù Ø´Ø¯: {file_path}")
                    except:
                        pass
        else:
            print("âš ï¸ Ø§Ø¯ØºØ§Ù… Ù…Ù…Ú©Ù† Ù†Ø¨ÙˆØ¯. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø­ÙØ¸ Ø´Ø¯Ù†Ø¯.")
    
    # Create zip file if no merge
    if not final_audio_file and len(generated_files) > 1:
        zip_filename = f"{output_base_name}_all_parts.zip"
        create_zip_file(generated_files, zip_filename)

    # Play the audio
    if final_audio_file and os.path.exists(final_audio_file):
        print(f"â–¶ï¸ Ù¾Ø®Ø´ ÙØ§ÛŒÙ„ Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡: {final_audio_file}")
        display(Audio(final_audio_file, autoplay=True))
    elif generated_files and os.path.exists(generated_files[0]):
        print(f"â–¶ï¸ Ù¾Ø®Ø´ Ø§ÙˆÙ„ÛŒÙ† Ù‚Ø·Ø¹Ù‡: {generated_files[0]}")
        display(Audio(generated_files[0], autoplay=True))
    else:
        print("ğŸ›‘ Ù¾Ø®Ø´ ØµØ¯Ø§ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª Ø²ÛŒØ±Ø§ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

    return generated_files, final_audio_file
